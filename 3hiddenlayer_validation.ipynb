{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:03:16.333765Z",
     "iopub.status.busy": "2024-10-20T12:03:16.333377Z",
     "iopub.status.idle": "2024-10-20T12:03:30.617601Z",
     "shell.execute_reply": "2024-10-20T12:03:30.616648Z",
     "shell.execute_reply.started": "2024-10-20T12:03:16.333721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-20T12:03:36.314098Z",
     "iopub.status.busy": "2024-10-20T12:03:36.313578Z",
     "iopub.status.idle": "2024-10-20T12:04:36.325194Z",
     "shell.execute_reply": "2024-10-20T12:04:36.324347Z",
     "shell.execute_reply.started": "2024-10-20T12:03:36.314052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Az1o3AfUM73lGlpXVsU_XvDBokFobk5j\n",
      "From (redirected): https://drive.google.com/uc?id=1Az1o3AfUM73lGlpXVsU_XvDBokFobk5j&confirm=t&uuid=0cb97e15-c029-4aec-a148-b795d9a63f65\n",
      "To: /kaggle/working/test.zip\n",
      "100%|██████████| 4.71G/4.71G [00:56<00:00, 84.0MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "\n",
    "file_id = '1Az1o3AfUM73lGlpXVsU_XvDBokFobk5j'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "output = 'test.zip'  \n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:04:36.327493Z",
     "iopub.status.busy": "2024-10-20T12:04:36.327062Z",
     "iopub.status.idle": "2024-10-20T12:06:22.147339Z",
     "shell.execute_reply": "2024-10-20T12:06:22.146543Z",
     "shell.execute_reply.started": "2024-10-20T12:04:36.327452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "local_zip_path = '/kaggle/working/test.zip'\n",
    "\n",
    "local_extract_path = '/kaggle/working/'\n",
    "\n",
    "import os\n",
    "os.makedirs(local_extract_path, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(local_zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(local_extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:06:57.668317Z",
     "iopub.status.busy": "2024-10-20T12:06:57.667574Z",
     "iopub.status.idle": "2024-10-20T12:07:00.336381Z",
     "shell.execute_reply": "2024-10-20T12:07:00.335439Z",
     "shell.execute_reply.started": "2024-10-20T12:06:57.668276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:07:00.338872Z",
     "iopub.status.busy": "2024-10-20T12:07:00.338298Z",
     "iopub.status.idle": "2024-10-20T12:07:05.000608Z",
     "shell.execute_reply": "2024-10-20T12:07:04.999718Z",
     "shell.execute_reply.started": "2024-10-20T12:07:00.338829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1EwCM0LgqqoHqCWkIjHffgzl_WxF2eirz\n",
      "To: /kaggle/working/files.csv\n",
      "100%|██████████| 4.69M/4.69M [00:00<00:00, 111MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'files.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id = '1EwCM0LgqqoHqCWkIjHffgzl_WxF2eirz'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "\n",
    "# Download the file\n",
    "output = 'files.csv'  \n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:09:18.599073Z",
     "iopub.status.busy": "2024-10-20T12:09:18.598433Z",
     "iopub.status.idle": "2024-10-20T12:09:52.086156Z",
     "shell.execute_reply": "2024-10-20T12:09:52.085035Z",
     "shell.execute_reply.started": "2024-10-20T12:09:18.599035Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "66926\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "df = pd.read_csv('files.csv')\n",
    "df = df[df['Set'] == 'eval']  # Only hidden validation set\n",
    "\n",
    "mfcc_features = []\n",
    "cqt_features = []\n",
    "labels = []\n",
    "\n",
    "i = 1\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    mfcc = np.load('mfccs/' + row['Name'] + \".npy\")\n",
    "    mfcc_features.append(mfcc)\n",
    "\n",
    "    cqt = np.load(\"cqts/\" + row['Name'] + \".npy\")\n",
    "    cqt_features.append(cqt)\n",
    "\n",
    "    labels.append(1 if row['Type'] == 'spoof' else 0)\n",
    "    i += 1\n",
    "    if(i==50000):\n",
    "      break\n",
    "# Load validation data\n",
    "print(i)\n",
    "df = pd.read_csv('files.csv')\n",
    "df = df[df['Set'] == 'hidden']\n",
    "# Convert lists to numpy arrays\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    mfcc = np.load('mfccs/' + row['Name'] + \".npy\")\n",
    "    mfcc_features.append(mfcc)\n",
    "\n",
    "    cqt = np.load(\"cqts/\" + row['Name'] + \".npy\")\n",
    "    cqt_features.append(cqt)\n",
    "\n",
    "    # Convert label to binary (1 for spoof, 0 for bonafide)\n",
    "    labels.append(1 if row['Type'] == 'spoof' else 0)\n",
    "    i += 1\n",
    "\n",
    "print(i)\n",
    "mfcc_features = np.array(mfcc_features)  # Shape: (num_samples, num_mfcc, timesteps)\n",
    "cqt_features = np.array(cqt_features)    # Shape: (num_samples, num_cqt, timesteps)\n",
    "labels = np.array(labels)                # Shape: (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:09:52.088500Z",
     "iopub.status.busy": "2024-10-20T12:09:52.088180Z",
     "iopub.status.idle": "2024-10-20T12:09:52.094375Z",
     "shell.execute_reply": "2024-10-20T12:09:52.093444Z",
     "shell.execute_reply.started": "2024-10-20T12:09:52.088466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66925, 1, 13, 150)\n",
      "(66925, 1, 84, 150)\n"
     ]
    }
   ],
   "source": [
    "# Add a channel dimension to MFCC and CQT features\n",
    "mfcc_features = np.expand_dims(mfcc_features, axis=1)  # Shape: (num_samples, 1, num_mfcc, timesteps)\n",
    "cqt_features = np.expand_dims(cqt_features, axis=1)    # Shape: (num_samples, 1, num_cqt, timesteps)\n",
    "print(mfcc_features.shape)\n",
    "print(cqt_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:09:52.095825Z",
     "iopub.status.busy": "2024-10-20T12:09:52.095539Z",
     "iopub.status.idle": "2024-10-20T12:09:53.610474Z",
     "shell.execute_reply": "2024-10-20T12:09:53.609545Z",
     "shell.execute_reply.started": "2024-10-20T12:09:52.095794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create TensorDataset for validation set\n",
    "val_dataset = TensorDataset(\n",
    "    torch.tensor(mfcc_features, dtype=torch.float32),\n",
    "    torch.tensor(cqt_features, dtype=torch.float32),\n",
    "    torch.tensor(labels, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "# Create DataLoader\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:09:53.612074Z",
     "iopub.status.busy": "2024-10-20T12:09:53.611713Z",
     "iopub.status.idle": "2024-10-20T12:09:53.629887Z",
     "shell.execute_reply": "2024-10-20T12:09:53.628957Z",
     "shell.execute_reply.started": "2024-10-20T12:09:53.612033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Replace the with required class (2 or 3 hidden layers)\n",
    "\n",
    "class Res2NetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scales=4):\n",
    "        super(Res2NetBlock, self).__init__()\n",
    "        self.scales = scales\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels // scales, out_channels // scales, kernel_size=3, padding=1, bias=False)\n",
    "            for _ in range(scales - 1)\n",
    "        ])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm2d(out_channels // scales) for _ in range(scales - 1)])\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_channels // 2, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        xs = torch.split(out, out.size(1) // self.scales, dim=1)\n",
    "\n",
    "        for i in range(1, self.scales):\n",
    "            if i == 1:\n",
    "                output = xs[i]\n",
    "            else:\n",
    "                output = output + xs[i]\n",
    "            output = self.relu(self.bns[i-1](self.convs[i-1](output)))\n",
    "\n",
    "        out = torch.cat((xs[0], output), dim=1)\n",
    "\n",
    "        out = self.relu(self.bn3(self.conv3(out)))\n",
    "\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "class AudioSpoofingRes2Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioSpoofingRes2Net, self).__init__()\n",
    "\n",
    "        self.mfcc_res2net = Res2NetBlock(in_channels=1, out_channels=32, scales=4)\n",
    "        self.cqt_res2net = Res2NetBlock(in_channels=1, out_channels=32, scales=4)\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(115200,4096)\n",
    "        self.fc_extra = nn.Linear(4096,2048)\n",
    "        self.fc2 = nn.Linear(2048, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)  # Output layer\n",
    "\n",
    "    def forward(self, mfcc, cqt):\n",
    "        mfcc_output = self.mfcc_res2net(mfcc)\n",
    "        cqt_output = self.cqt_res2net(cqt)\n",
    "\n",
    "        mfcc_output = mfcc_output.view(mfcc_output.size(0), -1)\n",
    "        cqt_output = cqt_output.view(cqt_output.size(0), -1)\n",
    "\n",
    "        combined = torch.cat((mfcc_output, cqt_output), dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = F.relu(self.fc_extra(x))  # Pass through the new hidden layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:15:28.733954Z",
     "iopub.status.busy": "2024-10-20T12:15:28.733060Z",
     "iopub.status.idle": "2024-10-20T12:16:08.406435Z",
     "shell.execute_reply": "2024-10-20T12:16:08.405171Z",
     "shell.execute_reply.started": "2024-10-20T12:15:28.733897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=17T9mGl5X7135FVjT7V-oBB0gz3hOgzSy\n",
      "From (redirected): https://drive.google.com/uc?id=17T9mGl5X7135FVjT7V-oBB0gz3hOgzSy&confirm=t&uuid=30a7ffcc-d2ff-4489-a712-5bdc3672e9d5\n",
      "To: /kaggle/working/res2net.pth\n",
      "100%|██████████| 1.92G/1.92G [00:31<00:00, 60.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'res2net.pth'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id = '17T9mGl5X7135FVjT7V-oBB0gz3hOgzSy' \n",
    "\n",
    "destination = 'res2net.pth' \n",
    "gdown.download(f'https://drive.google.com/uc?id={file_id}', destination, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-20T12:16:42.428549Z",
     "iopub.status.busy": "2024-10-20T12:16:42.427821Z",
     "iopub.status.idle": "2024-10-20T12:17:30.754529Z",
     "shell.execute_reply": "2024-10-20T12:17:30.753604Z",
     "shell.execute_reply.started": "2024-10-20T12:16:42.428509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3972786009.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('res2net.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8187\n",
      "Confusion Matrix:\n",
      "[[ 6055   903]\n",
      " [11229 48738]]\n",
      "Precision: 0.9818\n",
      "Recall: 0.8127\n",
      "F1 Score: 0.8893\n",
      "EER: 0.1298 at threshold: 1.0000\n",
      "t-DCF at all thresholds:\n",
      "[0.95       0.24277968 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = AudioSpoofingRes2Net().to(device)\n",
    "model.load_state_dict(torch.load('res2net.pth', map_location=device))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Variables to store predictions and labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for mfcc_batch, cqt_batch, label_batch in val_loader:\n",
    "        mfcc_batch = mfcc_batch.to(device)\n",
    "        cqt_batch = cqt_batch.to(device)\n",
    "        label_batch = label_batch.to(device)\n",
    "\n",
    "        label_batch = label_batch.squeeze()  # Remove any extra dimensions\n",
    "\n",
    "        # Forward pass: Get predictions from the model\n",
    "        outputs = model(mfcc_batch, cqt_batch)\n",
    "\n",
    "        # Apply a threshold of 0.5 to get binary predictions (1 for spoof, 0 for bonafide)\n",
    "        predictions = (outputs.squeeze() >= 0.5).float()\n",
    "\n",
    "        # Append the predictions and true labels for later analysis\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "\n",
    "# Convert predictions and labels to NumPy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def compute_eer(labels, scores):\n",
    "    # Compute False Positive Rate (FPR) and True Positive Rate (TPR) at different thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "\n",
    "    # False Rejection Rate (FRR) = 1 - True Positive Rate (TPR)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # Find the point where FPR and FNR intersect (Equal Error Rate)\n",
    "    eer_threshold = thresholds[np.nanargmin(np.absolute(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.absolute(fnr - fpr))]\n",
    "\n",
    "    return eer, eer_threshold\n",
    "\n",
    "# Assuming `all_labels` are true labels and `outputs` are model probabilities (before thresholding)\n",
    "eer, eer_threshold = compute_eer(all_labels, all_predictions)\n",
    "print(f'EER: {eer:.4f} at threshold: {eer_threshold:.4f}')\n",
    "\n",
    "\n",
    "# Define the t-DCF parameters (costs and priors)\n",
    "Pspoof = 0.05  # Prior probability of spoof\n",
    "Pbonafide = 1 - Pspoof  # Prior probability of bonafide\n",
    "Cost_miss = 1  # Cost of missed detection (bonafide misclassified as spoof)\n",
    "Cost_false_alarm = 10  # Cost of false alarm (spoof misclassified as bonafide)\n",
    "\n",
    "# Compute t-DCF\n",
    "def compute_tDCF(fpr, fnr):\n",
    "    tDCF = Pbonafide * Cost_miss * fnr + Pspoof * Cost_false_alarm * fpr\n",
    "    return tDCF\n",
    "\n",
    "# Compute FPR and FNR at the EER threshold\n",
    "fpr_eer, tpr_eer, _ = roc_curve(all_labels, all_predictions)\n",
    "fnr_eer = 1 - tpr_eer\n",
    "\n",
    "# Compute t-DCF at the EER threshold\n",
    "tDCF_eer = compute_tDCF(fpr_eer, fnr_eer)\n",
    "\n",
    "# Print the t-DCF array\n",
    "print(\"t-DCF at all thresholds:\")\n",
    "print(tDCF_eer)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
